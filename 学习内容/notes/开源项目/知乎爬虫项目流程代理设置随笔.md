首先在设计代理爬信息的的时候 ，有的代理可能会出现不能用的情况。那么就需要在这些中做下处理。把这些修改掉。

首先设置一个任务bean  ，这个bean的目的也有在数据库中的映射，因为可以把这个功能改成 任务扫描的实体 。然后数据库中设计成任务的执行结果。

数据表设计为：

|  属性名  |  字段  |  内容  |  
- | :-: | -: 
主键| |


 设计流程：
- 这个是个代理 需要每天的去更新 还有个就是 每次在用的时候首先先去判断是否 超过我们的次数限制还有失败的概率 是否超过需要的了。
- 这样的话 那就是这个任务就是每天定时的开始执行获取ip代理即可 。
- 不能每次都得用本地ip去获取还得需要用代理去获取这样的话也要考虑到这个执行的时候去获取代理ip的使用。那么 关于这方面的方法 就封装成通用的。
- 首先在放入ip池的时候 首先判断时候更新过了 没有更新过的话在执行更新  先根据redis 中的时间去更新 。这个时间设置为每天的1点。然后如果更新成功后将这个时间增加一天。
- 取得这个时间后先判断当前时间是否是 小于今天的23点59:59的 ，如果符合， 代表今天还没有更新 那就去 代理池中取数据，如果为空，用本地的ip ，不为空 判断 下取出来的ip 是否 失败次数超过三次，并且失败率是超过60% ，如果符合 删除这个ip，不符合那么就是用这个ip执行。  这个方法最好加锁然后。然后让其循环不断的获取ip 直到获取到需要的ip数据。
- 那么 就去爬取页面 来获取 爬虫代理 ip入库。
- 需要把所有爬取的页面都去入到redis中
------------------------------------------------------------------------------
如果 要爬其他页面的那么直接去根据上面写的获取代理ip的方法然后去爬取相关页面 ，再写 业务逻辑。


